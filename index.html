<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Xiangjian (Shawn) Liu ‚Äî Home</title>
  <meta name="description" content="Personal academic homepage">
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <!-- SVG Filter for Glow Effect -->
  <svg style="position: absolute; width: 0; height: 0;">
    <defs>
      <filter id="glow">
        <feGaussianBlur stdDeviation="8" result="coloredBlur"/>
        <feMerge>
          <feMergeNode in="coloredBlur"/>
          <feMergeNode in="SourceGraphic"/>
        </feMerge>
      </filter>
    </defs>
  </svg>

  <header class="site-header">
    <div class="container">
      <h1 class="site-title">Xiangjian (Shawn) Liu</h1>
      <p class="site-subtitle">CS @ UC Irvine ¬∑ AI/ML ¬∑ Neurosymbolic AI ¬∑ Reasoning ¬∑ Secure ML Inference</p>
      <nav class="site-nav">
        <a href="#about">About</a>
        <a href="#research">Research</a>
        <a href="#publications">Publications</a>
        <a href="#projects">Projects</a>
        <a href="#teaching">Teaching</a>
        <a href="#contact">Contact</a>
      </nav>
    </div>
  </header>

  <main class="container">
    <section id="about">
      <h2>About</h2>
      <div class="about-content">
        <div class="about-text">
          <p>üß† I'm an undergraduate researcher in Computer Science at UC Irvine ('26). I work on neuro-symbolic AI, brain‚Äëinspired learning (HDC), multimodal models, and secure inference in neural networks (CKKS‚ÄëFHE). I'm very grateful for the opportunity to work with Prof. Mohsen Imani for my undergraduate research.</p>
          <ul class="meta">
            <li>üî¨ Current: BiasLab @ UCI</li>
            <li>üèÇ Hobbies: Snowboarding, music, gaming</li>
            <li>üéµ Favorite Artists: D'Angelo, Dijon, Mkgee (Corresponding fave albums below)</li>
            <li>üéÆ Favorite Game: Cyberpunk 2077</li>
          </ul>
          <div class="album-covers">
            <img src="assets/dangelo_voodoo_cover.jpeg" alt="D'Angelo - Voodoo album cover" />
            <img src="assets/Dijon_Absolutely_AlbumCover.jpeg" alt="Dijon - Absolutely album cover" />
            <img src="assets/mkgee_twostart_cover.jpg" alt="Mkgee - Two Star & the Dream Police album cover" />
          </div>
        </div>
        <div class="about-image">
          <img src="assets/self_picture_1.jpg" alt="Shawn Liu with cats Coconut and Kumquat" />
          <p class="image-caption">With my cats Coconut (left) 
            & Kumquat (right) üê±üê±</p>
        </div>
      </div>
    </section>

    <section id="research">
      <h2>Research</h2>
      <div class="cards-carousel">
        <article class="card">
          <h3>Secure & Efficient Neurosymbolic Reasoning</h3>
          <p>First-author <strong>IEEE TAI</strong> paper introducing a neurosymbolic AI framework that integrates open-vocabulary vision transformers with <strong>CKKS-based Fully Homomorphic Encryption</strong> for secure cloud reasoning. I led FHE implementation in Microsoft SEAL, developed the noise-injection simulator for encrypted GNN inference, and co-designed the MissionGNN architecture for privacy-preserving video anomaly detection. Corresponding author; rebuttal completed.</p>
          <p class="tags">FHE ¬∑ GNN ¬∑ Neurosymbolic AI ¬∑ Privacy-Preserving ML</p>
          <p><a href="#" aria-disabled="true">IEEE TAI (rebuttal - in review)</a> ¬∑ <a href="#" class="read-more" data-modal="secure-neurosymbolic">Read more ‚Üí</a></p>
        </article>        
        <article class="card">
          <h3>Geometric Priors for World Models</h3>
          <p>Using Vector Symbolic Architecture (VSA) to build generalizable world models with learned group structure. Achieved 87.5% zero-shot accuracy and 4√ó noise robustness. Contributed to ablation studies with world model grid.</p>
          <p class="tags">VSA ¬∑ World Models ¬∑ Generalization</p>
          <p><a href="https://openreview.net/forum?id=0MJ1PW2vE8" target="_blank" rel="noopener">NeurReps 2025</a> ¬∑ <a href="#" class="read-more" data-modal="geometric-priors">Read more ‚Üí</a></p>
        </article>
      </div>
    </section>

    <section id="projects">
      <h2>Projects</h2>
      <ul class="list">
        <li>
          <strong>AdamsFoods Wholesale App</strong> ‚Äî Full-stack JavaScript app with React client and Node.js/Express server. Features product catalog, checkout system, AWS S3 integration, and JWT authentication. 
          <a href="https://github.com/antsuh1028/AFStore">code</a> ¬∑ <a href="https://adamsfoodswholesale.com/">live website</a> ¬∑ <button class="read-more-btn" data-modal="adamsfood-app">‚ú® Read more<svg><rect></rect></svg></button>
        </li>
        <li>
          <strong>AdamsFoods Inventory Management System</strong> ‚Äî React frontend for back-office stock tracking with item CRUD, search/filter, and low-stock alerts. 
          <a href="https://github.com/antsuh1028/AdamsFoodsInventory">code</a> ¬∑ <button class="read-more-btn" data-modal="adamsfood-inventory">‚ú® Read more<svg><rect></rect></svg></button>
        </li>
        <li>
          <strong>Safe UAV Landing for U.S. Navy</strong> ‚Äî Custom pose estimation & reasoning model for safe UAV landing in adverse weather. Reduces casualty rates through intelligent deck clearance detection. 
          <button class="read-more-btn" data-modal="navy-uav">‚ú® Read more<svg><rect></rect></svg></button>
        </li>
        <li>
          <strong>Crash Anticipation</strong> ‚Äî VideoMAE model achieving 100% on AP, F1, and lead-time recall with real-time inference capability. Future: neurosymbolic reasoning for proactive collision avoidance. 
          <a href="https://github.com/ShawnnnLiu/Crash-Anticipation">code</a> ¬∑ <button class="read-more-btn" data-modal="crash-anticipation">‚ú® Read more<svg><rect></rect></svg></button>
        </li>
      </ul>

      <h3>Safe UAV Landing ‚Äî Demo</h3>
      <div class="demo-carousel">
        <div class="demo-item">
          <img src="assets/naval_aeriel demonstration.gif" alt="Navy UAV aerial demonstration" />
        </div>
        <div class="demo-item">
          <img src="assets/reasoning_1.png" alt="Object reasoning on aircraft carrier deck" />
        </div>
        <div class="demo-item">
          <img src="assets/reasoning_2.png" alt="Object reasoning detecting crew and vehicles" />
        </div>
      </div>

      <h3>Crash Anticipation ‚Äî Demo</h3>
      <div class="demo-carousel">
        <div class="demo-item">
          <img src="assets/ccd_000777.gif" alt="Crash Anticipation demo 1" />
        </div>
        <div class="demo-item">
          <img src="assets/ccd_000855.gif" alt="Crash Anticipation demo 2" />
        </div>
        <div class="demo-item">
          <img src="assets/ccd_001087.gif" alt="Crash Anticipation demo 3" />
        </div>
        <div class="demo-item">
          <img src="assets/ccd_001096.gif" alt="Crash Anticipation demo 4" />
        </div>
        <div class="demo-item">
          <img src="assets/ccd_001155.gif" alt="Crash Anticipation demo 5" />
        </div>
        <div class="demo-item">
          <img src="assets/ccd_001184.gif" alt="Crash Anticipation demo 6" />
        </div>
      </div>
    </section>

    <section id="teaching">
      <h2>Teaching & Service</h2>
      <ul class="list">
        <li>Learning Assistant ‚Äî ICS 33 (Spring 2025)</li>
        <li>Volunteer web dev for non‚Äëprofits (Feeding Pets of the Homeless)</li>
        <li>Youth In Action (YIA) - Student Counselor</li>
      </ul>
    </section>

    <section id="contact">
      <h2>Contact</h2>
      <ul class="list">
        <li>Email: <a href="mailto:xiangjl4@uci.edu">xiangjl4@uci.edu</a></li>
        <li>GitHub: <a href="https://github.com/ShawnnnLiu/" target="_blank" rel="noopener">ShawnnnLiu</a></li>
        <li>OpenReview: <a href="https://openreview.net/profile?id=%7EXiangjian_Liu1" target="_blank" rel="noopener">Xiangjian Liu</a></li>
        <li>LinkedIn: <a href="https://www.linkedin.com/in/xiangjian-shawn-liu/" target="_blank" rel="noopener">Xiangjian (Shawn) Liu</a></li>
      </ul>
    </section>
  </main>

  <!-- Hidden modal content templates -->
  <div hidden id="modal-content-secure-neurosymbolic" class="modal-content-template">
    <h2 id="modal-title">Secure & Efficient Neurosymbolic Reasoning</h2>
    <p class="tags">FHE ¬∑ GNN ¬∑ Neurosymbolic AI ¬∑ Privacy‚ÄëPreserving ML</p>
    <p>
      A neurosymbolic AI framework that integrates open‚Äëvocabulary vision transformers with CKKS‚Äëbased Fully
      Homomorphic Encryption (FHE) for secure cloud reasoning. Includes a noise‚Äëinjection simulator for encrypted
      GNN inference and a MissionGNN architecture for privacy‚Äëpreserving video anomaly detection.
    </p>
    <p>
      My role: led FHE implementation (Microsoft SEAL), built the encrypted‚Äëinference simulator, and co‚Äëdesigned the
      MissionGNN pipeline. Status: IEEE TAI (rebuttal in review).
    </p>
  </div>

  <div hidden id="modal-content-geometric-priors" class="modal-content-template">
    <h2 id="modal-title">Geometric Priors for Generalizable World Models via VSA</h2>
    <p class="tags">VSA ¬∑ World Models ¬∑ Generalization</p>
    <p>
      We introduce a world modeling framework grounded in Vector Symbolic Architecture (VSA) with learnable Fourier
      Holographic Reduced Representation encoders and group‚Äëstructured latent transitions via element‚Äëwise complex
      multiplication, enabling composition directly in latent space.
    </p>
    <ul class="list">
      <li>87.5% zero‚Äëshot accuracy on unseen state‚Äëaction pairs</li>
      <li>53.6% higher accuracy on 20‚Äëtimestep rollouts vs. MLP baseline</li>
      <li>4√ó robustness to noise</li>
    </ul>
    <p>My contribution: ablation studies with the world model grid. Post‚Äësubmission: MiniGrid experiments.</p>
    <p><a href="https://openreview.net/forum?id=0MJ1PW2vE8" target="_blank" rel="noopener">OpenReview</a></p>
  </div>

  <div hidden id="modal-content-adamsfood-app" class="modal-content-template">
    <h2 id="modal-title">AdamsFoods Wholesale App</h2>
    <p class="tags">Full-Stack ¬∑ React ¬∑ Node.js ¬∑ AWS S3 ¬∑ JWT Auth</p>
    <p>
      A comprehensive full-stack JavaScript application built with a React client and Node.js/Express server. The application serves as a wholesale platform with robust product management and user authentication.
    </p>
    <h3>Key Features</h3>
    <ul class="list">
      <li><strong>Product Catalog:</strong> Complete product browsing and management system</li>
      <li><strong>Shopping Cart & Checkout:</strong> Fully functional cart system with checkout workflow skeleton</li>
      <li><strong>AWS S3 Integration:</strong> Seamless media and document workflows using signed URL uploads with intelligent caching</li>
      <li><strong>JWT Authentication:</strong> Secure token-based authentication with role-based access control</li>
      <li><strong>Admin Routes:</strong> Protected admin endpoints with role guards for sensitive operations</li>
      <li><strong>REST API:</strong> Well-structured REST endpoints organized under <code>/server</code></li>
    </ul>
    <p><a href="https://github.com/antsuh1028/AFStore" target="_blank" rel="noopener">View Code</a> ¬∑ <a href="https://adamsfoodswholesale.com/" target="_blank" rel="noopener">Live Website</a></p>
  </div>

  <div hidden id="modal-content-adamsfood-inventory" class="modal-content-template">
    <h2 id="modal-title">AdamsFoods Inventory Management System</h2>
    <p class="tags">React ¬∑ Vercel ¬∑ Inventory Management ¬∑ CRUD</p>
    <p>
      A React-based frontend application (Create React App) designed for back-office inventory tracking and stock management. Deployed on Vercel for reliable, fast access.
    </p>
    <h3>Features</h3>
    <ul class="list">
      <li><strong>Item CRUD Operations:</strong> Complete Create, Read, Update, Delete functionality for inventory items</li>
      <li><strong>Advanced Search & Filter:</strong> Powerful search capabilities to quickly locate items</li>
      <li><strong>Low-Stock Alerts:</strong> Automatic flagging of items with low inventory levels</li>
      <li><strong>CSV Export:</strong> Export-friendly views for reporting and data analysis</li>
      <li><strong>Interactive Map:</strong> 3D Map of warehouse storage rooms and item locations</li>
    </ul>
    <p><a href="https://github.com/antsuh1028/AdamsFoodsInventory" target="_blank" rel="noopener">View Code</a></p>
  </div>

  <div hidden id="modal-content-navy-uav" class="modal-content-template">
    <h2 id="modal-title">Safe UAV Landing for U.S. Navy</h2>
    <p class="tags">Computer Vision ¬∑ Pose Estimation ¬∑ Reasoning ¬∑ CUI Dataset</p>
    <p>
      Through BiasLab & Prof. Mohsen Imani, I collaborated with the U.S. Navy to develop a custom computer vision system combining pose estimation and symbolic reasoning for safe autonomous UAV landing operations.
    </p>
    <h3>Problem Statement</h3>
    <p>
      Traditional UAV landing systems rely on legacy fixed-pattern optical markers, which perform poorly in adverse weather conditions, leading to increased casualty rates and mission failures. The Navy needed a more robust solution that could operate safely in challenging environments.
    </p>
    <h3>Solution</h3>
    <ul class="list">
      <li><strong>Pose Estimation Model:</strong> Custom-trained model for accurate UAV positioning relative to landing deck</li>
      <li><strong>Reasoning Module:</strong> Intelligent system that delays landing when crew members or obstacles are detected on the landing spot/deck</li>
      <li><strong>Weather Robustness:</strong> Significantly improved performance in bad weather conditions compared to legacy systems</li>
      <li><strong>Real-time Processing:</strong> Fast inference for time-critical landing decisions</li>
    </ul>
    <h3>Impact</h3>
    <p>
      The system reduces casualty rates by preventing landings when the deck is not clear, providing a crucial safety layer for naval aviation operations. Worked on CUI (Controlled Unclassified Information) dataset under appropriate clearances.
    </p>
  </div>

  <div hidden id="modal-content-crash-anticipation" class="modal-content-template">
    <h2 id="modal-title">Crash Anticipation</h2>
    <p class="tags">Computer Vision ¬∑ VideoMAE ¬∑ Autonomous Driving ¬∑ Neurosymbolic AI</p>
    <p>
      A cutting-edge video analysis system for predicting vehicle crashes before they occur, with future integration of neurosymbolic reasoning for actionable collision avoidance commands.
    </p>
    <h3>Current Performance (VideoMAE Baseline)</h3>
    <ul class="list">
      <li><strong>100% Accuracy:</strong> Perfect scores on AP (Average Precision), F1, and lead-time recall metrics</li>
      <li><strong>Real-time Inference:</strong> Capable of real-time processing with an NVIDIA 5070 Ti GPU</li>
      <li><strong>High Reliability:</strong> Demonstrated robust crash prediction across diverse scenarios</li>
    </ul>
    <h3>Current Limitations</h3>
    <p>
      The VideoMAE model's computational cost is too high for practical deployment on mobile devices or embedded systems in vehicles. This limits real-world applicability despite excellent performance.
    </p>
    <h3>Next Steps: Model Compression</h3>
    <p>
      Exploring smaller, more efficient models such as <strong>MobileNetV2.0</strong> that can run on resource-constrained devices while maintaining similar performance levels. Goal: Enable deployment on standard automotive hardware.
    </p>
    <h3>Future Direction: Neurosymbolic Reasoning</h3>
    <p>
      Beyond simple crash prediction, the vision is to integrate a <strong>symbolic reasoning module</strong> that can:
    </p>
    <ul class="list">
      <li><strong>Provide Direct Commands:</strong> Issue specific avoidance instructions (e.g., "turn left 15¬∞", "brake immediately", "accelerate to avoid rear collision")</li>
      <li><strong>Infer Vehicle Dynamics:</strong> Calculate incoming vehicle speed, trajectory, and direction in real-time</li>
      <li><strong>Reason About Scenarios:</strong> Use symbolic reasoning to evaluate multiple avoidance strategies and select optimal actions</li>
      <li><strong>Proactive Collision Avoidance:</strong> Transform from reactive warning system to proactive safety system that prevents crashes through intelligent intervention</li>
    </ul>
    <p>
      This neurosymbolic approach combines the perceptual power of deep learning with the interpretability and logical reasoning of symbolic AI, aligning with my broader research focus on neurosymbolic reasoning systems.
    </p>
    <p><a href="https://github.com/ShawnnnLiu/Crash-Anticipation" target="_blank" rel="noopener">View Code</a></p>
  </div>

  <!-- Modal overlay -->
  <div id="modal" class="modal" aria-hidden="true">
    <div class="modal-backdrop" data-close></div>
    <div class="modal-dialog" role="dialog" aria-modal="true" aria-labelledby="modal-title">
      <button class="modal-close" data-close aria-label="Close">√ó</button>
      <div id="modal-body"></div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container">
      <p>¬© <span id="year"></span> Shawn Liu</p>
    </div>
  </footer>

  <script>
    // Modal helpers
    (function() {
      const modal = document.getElementById('modal');
      const body = document.getElementById('modal-body');
      function openModal(key) {
        const tpl = document.getElementById(`modal-content-${key}`);
        if (!tpl) return;
        body.innerHTML = tpl.innerHTML;
        modal.classList.add('open');
        modal.setAttribute('aria-hidden', 'false');
        document.body.style.overflow = 'hidden';
      }
      function closeModal() {
        modal.classList.remove('open');
        modal.setAttribute('aria-hidden', 'true');
        body.innerHTML = '';
        document.body.style.overflow = '';
      }
      modal.addEventListener('click', (e) => {
        if (e.target.matches('[data-close]')) closeModal();
      });
      document.addEventListener('keydown', (e) => {
        if (e.key === 'Escape') closeModal();
      });
      document.addEventListener('click', (e) => {
        const link = e.target.closest('.read-more, .read-more-btn');
        if (!link) return;
        e.preventDefault();
        const key = link.getAttribute('data-modal');
        openModal(key);
      });
    })();

    // Carousel scroll function
    function scrollCarousel(direction) {
      const carousel = document.querySelector('.cards-carousel');
      const cardWidth = 320; // card width + gap
      const scrollAmount = (cardWidth + 16) * direction;
      carousel.scrollBy({ left: scrollAmount, behavior: 'smooth' });
    }

    document.getElementById('year').textContent = new Date().getFullYear();
    // Optional publications rendering (only if #pubs exists)
    (function() {
      const wrap = document.getElementById('pubs');
      if (!wrap) return;
      fetch('publications.json')
        .then(r => r.json())
        .then(items => {
          if (!Array.isArray(items) || items.length === 0) {
            wrap.innerHTML = '<p>No publications yet.</p>';
            return;
          }
          wrap.innerHTML = '';
          items.forEach(p => {
            const el = document.createElement('div');
            el.className = 'pub';
            const authors = (p.authors || []).join(', ');
            const venue = [p.venue, p.year].filter(Boolean).join(', ');
            el.innerHTML = `
              <p class="title">${p.title || ''}</p>
              <p class="by">${authors}</p>
              <p class="venue">${venue}</p>
              <p class="links">
                ${p.doi ? `<a href="${p.doi}" target="_blank" rel="noopener">DOI</a>` : ''}
                ${p.arxiv ? `<a href="${p.arxiv}" target="_blank" rel="noopener">arXiv</a>` : ''}
                ${p.code ? `<a href="${p.code}" target="_blank" rel="noopener">Code</a>` : ''}
                ${p.poster ? `<a href="${p.poster}" target="_blank" rel="noopener">Poster</a>` : ''}
              </p>`;
            wrap.appendChild(el);
          });
        })
        .catch(() => { if (wrap) wrap.innerHTML = '<p>(Could not load publications.json)</p>'; });
    })();

    // (demos removed; single GIF is rendered statically in markup)
  </script>
</body>
</html>
