<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Xiangjian (Shawn) Liu ‚Äî Home</title>
  <meta name="description" content="Personal academic homepage">
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <!-- SVG Filter for Glow Effect -->
  <svg style="position: absolute; width: 0; height: 0;">
    <defs>
      <filter id="glow">
        <feGaussianBlur stdDeviation="8" result="coloredBlur"/>
        <feMerge>
          <feMergeNode in="coloredBlur"/>
          <feMergeNode in="SourceGraphic"/>
        </feMerge>
      </filter>
    </defs>
  </svg>

  <header class="site-header">
    <div class="container">
      <h1 class="site-title">Xiangjian (Shawn) Liu</h1>
      <p class="site-subtitle">CS @ UC Irvine ¬∑ AI/ML ¬∑ Neurosymbolic AI ¬∑ Reasoning ¬∑ Secure ML Inference</p>
      <nav class="site-nav">
        <a href="#about">About</a>
        <a href="#research">Research</a>
        <a href="#projects">Projects</a>
        <a href="#teaching">Teaching</a>
        <a href="#contact">Contact</a>
      </nav>
    </div>
  </header>

  <main class="container">
    <section id="about">
      <h2>About</h2>
      <div class="about-content">
        <div class="about-text">
          <p>üß† I'm an undergraduate researcher in Computer Science at UC Irvine ('26). I work on neuro-symbolic AI, brain‚Äëinspired learning (HDC), multimodal models, and secure inference in neural networks (CKKS‚ÄëFHE). I'm very grateful for the opportunity to work with Prof. Mohsen Imani for my undergraduate research.</p>
          <ul class="meta">
            <li>üî¨ Current: BiasLab @ UCI</li>
            <li>üèÇ Hobbies: Snowboarding, music, gaming</li>
            <li>üéµ Favorite Artists: D'Angelo, Dijon, Mkgee (Corresponding fave albums below)</li>
            <li>üéÆ Favorite Game: Cyberpunk 2077</li>
          </ul>
          <div class="album-covers">
            <a href="https://www.youtube.com/playlist?list=PLj0iicDFTqJq8CcEMDS1VUbT0DPjFYOm1" target="_blank" rel="noopener" title="Listen to D'Angelo - Voodoo on YouTube">
              <img src="assets/dangelo_voodoo_cover.jpeg" alt="D'Angelo - Voodoo album cover" />
            </a>
            <a href="https://www.youtube.com/watch?v=FEkOYs6aWIg" target="_blank" rel="noopener" title="Listen to Dijon - Absolutely on YouTube">
              <img src="assets/Dijon_Absolutely_AlbumCover.jpeg" alt="Dijon - Absolutely album cover" />
            </a>
            <a href="https://www.youtube.com/watch?v=aZ13RneU1S0" target="_blank" rel="noopener" title="Listen to Mkgee - Two Star & the Dream Police on YouTube">
              <img src="assets/mkgee_twostart_cover.jpg" alt="Mkgee - Two Star & the Dream Police album cover" />
            </a>
          </div>
        </div>
        <div class="about-image">
          <img src="assets/self_picture_1.jpg" alt="Shawn Liu with cats Coconut and Kumquat" class="clickable-image" data-modal="cat-collage" />
          <p class="image-caption">With my cats Coconut (left) 
            & Kumquat (right) üê±üê± <br><small style="color: var(--accent); cursor: default;">Click photo for more cat pics! üì∏</small></p>
        </div>
      </div>
    </section>

    <section id="research">
      <h2>Research</h2>
      <div class="cards-carousel">
        <article class="card">
          <h3>Brain-Inspired Reasoning under Homomorphic Encryption</h3>
          <p>Privacy-preserving neurosymbolic framework executing inference entirely under CKKS-FHE while preserving HDC-based reasoning robustness. Maintains >90% accuracy on encrypted graph inference with 4√ó reduction in bootstrapping overhead through noise-adaptive scheduling. Lead author; rebuttal completed.</p>
          <p class="tags">FHE ¬∑ HDC ¬∑ Neurosymbolic AI ¬∑ Privacy-Preserving ML</p>
          <p><a href="#" aria-disabled="true">IEEE TAI 2026 (under review)</a> ¬∑ <button class="read-more-btn" data-modal="secure-neurosymbolic">‚ú® Read more<svg><rect></rect></svg></button></p>
        </article>        
        <article class="card">
          <h3>Geometric Priors for World Models</h3>
          <p>Using Vector Symbolic Architecture (VSA) to build generalizable world models with learned group structure. Achieved 87.5% zero-shot accuracy and 4√ó noise robustness. Contributed to ablation studies with world model grid.</p>
          <p class="tags">VSA ¬∑ World Models ¬∑ Generalization</p>
          <p><a href="https://openreview.net/forum?id=0MJ1PW2vE8" target="_blank" rel="noopener">NeurIPS 2025 Workshop</a> ¬∑ <button class="read-more-btn" data-modal="geometric-priors">‚ú® Read more<svg><rect></rect></svg></button></p>
        </article>
        <article class="card">
          <h3>Cross-Modal Event Encoder: Bridging Image‚ÄìText Knowledge to Event Streams</h3>
          <p>Extending CLIP's zero-shot capabilities to event-based vision, bridging asynchronous event data with image-text representations. Achieved +19% zero-shot accuracy over prior methods with cross-modal retrieval across five modalities. Contributed attention visualization pipeline.</p>
          <p class="tags">Event-based Vision ¬∑ CLIP ¬∑ Cross-Modality</p>
          <p><a href="https://arxiv.org/abs/2412.03093" target="_blank" rel="noopener">WACV 2026</a> ¬∑ <button class="read-more-btn" data-modal="event-clip">‚ú® Read more<svg><rect></rect></svg></button></p>
        </article>
        <article class="card">
          <h3>Optimal Hyperdimensional Representation</h3>
          <p>First universal HDC encoding framework that adapts dynamically between learning and cognitive reasoning. Achieves 95% learning accuracy with correlated encodings and 100% decoding accuracy under exclusive encodings. Quantifies correlation-separation trade-off for brain-like reasoning.</p>
          <p class="tags">HDC ¬∑ Cognitive Computation ¬∑ Neural-Symbolic</p>
          <p><a href="#" aria-disabled="true">Frontiers in AI (in review)</a> ¬∑ <button class="read-more-btn" data-modal="optimal-hdc">‚ú® Read more<svg><rect></rect></svg></button></p>
        </article>
        <article class="card">
          <h3>Hardware-Efficient HDC with FeFET Non-Idealities</h3>
          <p>Energy-efficient HDC framework eliminating non-linear activations by harnessing FeFET device non-idealities. Achieves 33-41% energy reduction and 17% area savings through stacked complementary crossbars while maintaining robust performance under analog computation noise.</p>
          <p class="tags">HDC ¬∑ Compute-in-Memory ¬∑ Neuromorphic ¬∑ Efficient AI</p>
          <p><a href="#" aria-disabled="true">IEEE TCAS-I (in review)</a> ¬∑ <button class="read-more-btn" data-modal="efficient-hdc">‚ú® Read more<svg><rect></rect></svg></button></p>
        </article>
      </div>
    </section>

    <section id="projects">
      <h2>Projects</h2>
      <ul class="list">
        <li>
          <strong>AdamsFoods Wholesale</strong> ‚Äî Full-stack JavaScript app with React client and Node.js/Express server. Features product catalog, checkout system, AWS S3 integration, and JWT authentication. 
          <a href="https://github.com/antsuh1028/AFStore">code</a> ¬∑ <a href="https://adamsfoodswholesale.com/">live website</a> ¬∑ <button class="read-more-btn" data-modal="adamsfood-app">‚ú® Read more<svg><rect></rect></svg></button>
        </li>
        <li>
          <strong>AdamsFoods Inventory Management System</strong> ‚Äî React frontend for back-office stock tracking with item CRUD, search/filter, and low-stock alerts. 
          <a href="https://github.com/antsuh1028/AdamsFoodsInventory">code</a> ¬∑ <button class="read-more-btn" data-modal="adamsfood-inventory">‚ú® Read more<svg><rect></rect></svg></button>
        </li>
        <li>
          <strong>Feeding Pets of the Homeless Dashboard</strong> ‚Äî Full-stack donation management platform for CTC @ UCI partnering with non-profit. React/TypeScript frontend with Node.js/Express backend, PostgreSQL database, Firebase Auth, and role-based access control. 
          <a href="https://github.com/ctc-uci/fph-frontend">frontend</a> ¬∑ <a href="https://github.com/ctc-uci/fph-backend">backend</a> ¬∑ <button class="read-more-btn" data-modal="fph-dashboard">‚ú® Read more<svg><rect></rect></svg></button>
        </li>
        <li>
          <strong>Safe UAV Landing for U.S. Navy</strong> ‚Äî Custom pose estimation & reasoning model for safe UAV landing in adverse weather. Reduces casualty rates through intelligent deck clearance detection. 
          <button class="read-more-btn" data-modal="navy-uav">‚ú® Read more<svg><rect></rect></svg></button>
        </li>
        <li>
          <strong>Crash Anticipation</strong> ‚Äî VideoMAE model achieving 100% on AP, F1, and lead-time recall with real-time inference capability. Future: neurosymbolic reasoning for proactive collision avoidance. 
          <a href="https://github.com/ShawnnnLiu/Crash-Anticipation">code</a> ¬∑ <button class="read-more-btn" data-modal="crash-anticipation">‚ú® Read more<svg><rect></rect></svg></button>
        </li>
      </ul>

      <h3>Safe UAV Landing ‚Äî Demo</h3>
      <div class="demo-carousel">
        <div class="demo-item">
          <img src="assets/naval_aeriel demonstration.gif" alt="Navy UAV aerial demonstration" />
        </div>
        <div class="demo-item">
          <img src="assets/reasoning_1.png" alt="Object reasoning on aircraft carrier deck" />
        </div>
        <div class="demo-item">
          <img src="assets/reasoning_2.png" alt="Object reasoning detecting crew and vehicles" />
        </div>
      </div>

      <h3>Crash Anticipation ‚Äî Demo</h3>
      <div class="demo-carousel">
        <div class="demo-item">
          <img src="assets/ccd_000777.gif" alt="Crash Anticipation demo 1" />
        </div>
        <div class="demo-item">
          <img src="assets/ccd_000855.gif" alt="Crash Anticipation demo 2" />
        </div>
        <div class="demo-item">
          <img src="assets/ccd_001087.gif" alt="Crash Anticipation demo 3" />
        </div>
        <div class="demo-item">
          <img src="assets/ccd_001096.gif" alt="Crash Anticipation demo 4" />
        </div>
        <div class="demo-item">
          <img src="assets/ccd_001155.gif" alt="Crash Anticipation demo 5" />
        </div>
        <div class="demo-item">
          <img src="assets/ccd_001184.gif" alt="Crash Anticipation demo 6" />
        </div>
      </div>
    </section>

    <section id="teaching">
      <h2>Teaching & Service</h2>
      <ul class="list">
        <li>Learning Assistant ‚Äî ICS 33 (Spring 2025)</li>
        <li>Web dev for non‚Äëprofits, pro bono (Feeding Pets of the Homeless)</li>
        <li>Youth In Action (YIA) - Student Counselor</li>
      </ul>
    </section>

    <section id="contact">
      <h2>Contact</h2>
      <ul class="list">
        <li>Email: <a href="mailto:xiangjl4@uci.edu">xiangjl4@uci.edu</a></li>
        <li>GitHub: <a href="https://github.com/ShawnnnLiu/" target="_blank" rel="noopener">ShawnnnLiu</a></li>
        <li>OpenReview: <a href="https://openreview.net/profile?id=%7EXiangjian_Liu1" target="_blank" rel="noopener">Xiangjian Liu</a></li>
        <li>LinkedIn: <a href="https://www.linkedin.com/in/xiangjian-shawn-liu/" target="_blank" rel="noopener">Xiangjian (Shawn) Liu</a></li>
      </ul>
    </section>
  </main>

  <!-- Hidden modal content templates -->
  <div hidden id="modal-content-secure-neurosymbolic" class="modal-content-template">
    <h2 id="modal-title">Robust Reasoning and Learning with Brain-Inspired Representations under Homomorphic Encryption</h2>
    <p class="tags">Privacy-Preserving AI ¬∑ Neuro-Symbolic Learning ¬∑ Homomorphic Encryption ¬∑ HDC</p>
    <p><strong>IEEE Transactions on Artificial Intelligence (2026, under review)</strong></p>
    <p>
      We propose a privacy-preserving neurosymbolic framework that executes inference entirely under CKKS Fully Homomorphic Encryption (FHE) while preserving the robustness and interpretability of Hyperdimensional Computing (HDC)-based reasoning. The framework introduces distributed bootstrapping to mitigate ciphertext-noise explosion across deep layers, balancing accuracy and compute cost.
    </p>

    <h3>Key Results</h3>
    <ul class="list">
      <li>Maintains <strong>>90% accuracy</strong> on encrypted graph inference without plaintext access</li>
      <li><strong>4√ó reduction</strong> in bootstrapping overhead through noise-adaptive scheduling</li>
      <li>Preserves symbolic structure of neural states under encrypted operations</li>
      <li>Robust performance across multiple graph-based reasoning tasks</li>
    </ul>

    <h3>Why Homomorphic Encryption?</h3>
    <p>
      Cloud-based AI inference poses significant privacy risks when handling sensitive data (medical records, financial information, biometric data). Traditional encryption requires decryption before processing, exposing data to potential breaches. Fully Homomorphic Encryption enables computation directly on encrypted data, ensuring privacy even in untrusted cloud environments.
    </p>
    <div class="research-figures">
      <figure class="research-figure-single">
        <img src="assets/research/WhyFHEframework.png" alt="Why FHE framework diagram" />
        <figcaption>FHE's security advantage: Data remains encrypted throughout the entire inference pipeline in untrusted cloud environments</figcaption>
      </figure>
    </div>

    <h3>Framework Overview</h3>
    <p>
      Our end-to-end neurosymbolic pipeline integrates HDC-based symbolic reasoning with CKKS-FHE operations. The framework employs distributed bootstrapping at strategic network layers to prevent noise accumulation while minimizing computational overhead. Graph Neural Networks operate entirely on encrypted representations, with symbolic decoding preserving interpretability.
    </p>
    <div class="research-figures">
      <figure class="research-figure-single">
        <img src="assets/research/OVERALLframework.png" alt="Overall framework architecture" />
        <figcaption>End-to-end neuro-symbolic FHE pipeline with distributed bootstrapping and symbolic decoding</figcaption>
      </figure>
    </div>

    <h3>Noise-Adaptive Bootstrapping</h3>
    <p>
      A critical challenge in FHE-based deep learning is ciphertext noise accumulation. Without proper noise management, encrypted operations cause accuracy to collapse as noise overwhelms the signal. Our distributed bootstrapping scheme strategically refreshes ciphertexts at high-noise layers, achieving a 4√ó reduction in bootstrapping overhead compared to naive per-layer approaches.
    </p>
    <div class="research-figures">
        <figcaption>Empirical analysis: Noise growth without bootstrapping leads to accuracy collapse. Our approach balances accuracy preservation with computational efficiency</figcaption>
      </figure>
    </div>

    <h3>Technical Innovation</h3>
    <ul class="list">
      <li><strong>SEAL-Based Implementation:</strong> Built on Microsoft SEAL library for CKKS operations</li>
      <li><strong>Noise Characterization:</strong> Empirical analysis of real noise distributions in encrypted GNN operations</li>
      <li><strong>Distributed Bootstrapping:</strong> Adaptive scheduling reduces compute cost by 75% while maintaining accuracy</li>
      <li><strong>Symbolic Preservation:</strong> HDC-based representations maintain interpretability under encryption</li>
      <li><strong>Graph Reasoning:</strong> Encrypted inference on graph-structured data for video anomaly detection</li>
    </ul>

    <h3>Applications</h3>
    <p>
      The framework enables privacy-preserving AI for sensitive domains:
    </p>
    <ul class="list">
      <li><strong>Healthcare:</strong> Encrypted medical diagnosis without exposing patient data</li>
      <li><strong>Finance:</strong> Fraud detection on encrypted transaction graphs</li>
      <li><strong>Surveillance:</strong> Privacy-preserving video anomaly detection in public spaces</li>
      <li><strong>IoT Security:</strong> Encrypted reasoning on edge device data</li>
    </ul>

    <p><strong>My contribution:</strong> Lead author and corresponding author. Designed and conducted SEAL-based experiments to characterize real noise distributions and evaluate CKKS performance under GNN operations. Implemented noise injection mechanisms and distributed bootstrapping schemes within the graph network to achieve robust encrypted reasoning. Led rebuttal process for IEEE TAI 2026.</p>
  </div>

  <div hidden id="modal-content-geometric-priors" class="modal-content-template">
    <h2 id="modal-title">Geometric Priors for Generalizable World Models via VSA</h2>
    <p class="tags">VSA ¬∑ World Models ¬∑ Generalization</p>
    <p><strong>NeurIPS 2025 Workshop on Symmetry and Geometry in Neural Representations</strong></p>
    <p>
      We introduce a world modeling framework grounded in Vector Symbolic Architecture (VSA) with learnable Fourier
      Holographic Reduced Representation encoders and group‚Äëstructured latent transitions via element‚Äëwise complex
      multiplication, enabling composition directly in latent space.
    </p>
    
    <h3>Key Results</h3>
    <ul class="list">
      <li>87.5% zero‚Äëshot accuracy on unseen state‚Äëaction pairs</li>
      <li>53.6% higher accuracy on 20‚Äëtimestep rollouts vs. MLP baseline</li>
      <li>4√ó robustness to noise</li>
    </ul>

    <h3>Structured State Representations</h3>
    <p>
      Our VSA-based model (FHRR) learns structured, grid-like state embeddings that preserve geometric relationships, while traditional MLP models produce unstructured representations.
    </p>
    <div class="research-figures">
      <div class="figure-pair">
        <figure class="research-figure">
          <img src="assets/research/figures-160.png" alt="FHRR state embeddings showing grid-like structure" />
          <figcaption>FHRR (VSA): Grid-like structured embeddings preserve spatial relationships</figcaption>
        </figure>
        <figure class="research-figure">
          <img src="assets/research/figures-159.png" alt="MLP unstructured embeddings" />
          <figcaption>MLP: Unstructured embeddings with no clear geometric pattern</figcaption>
        </figure>
      </div>
    </div>

    <h3>Superior Generalization</h3>
    <p>
      VSA (FHRR) demonstrates significantly better generalization on held-out data across different data holdout ratios, maintaining high accuracy even when large portions of training data are withheld.
    </p>
    <div class="research-figures">
      <figure class="research-figure-single">
        <img src="assets/research/figures-158.png" alt="Rollout performance comparison" />
        <figcaption>Rollout accuracy vs. data holdout ratio: VSA maintains strong performance while MLP degrades rapidly</figcaption>
      </figure>
    </div>

    <h3>Robustness to Noise</h3>
    <p>
      The VSA approach exhibits greater robustness to Gaussian noise compared to MLP baselines, maintaining near-perfect accuracy under significant noise perturbations.
    </p>
    <div class="research-figures">
      <figure class="research-figure-single">
        <img src="assets/research/figures-166.png" alt="Robustness to noise comparison" />
        <figcaption>1-step accuracy vs. Gaussian noise: VSA maintains >80% accuracy even with noise std of 5, while MLP drops to ~20%</figcaption>
      </figure>
    </div>

    <p><strong>My contribution:</strong> ablation studies with the world model grid. Post‚Äësubmission: MiniGrid experiments.</p>
    <p><a href="https://openreview.net/forum?id=0MJ1PW2vE8" target="_blank" rel="noopener">OpenReview</a></p>
  </div>

  <div hidden id="modal-content-event-clip" class="modal-content-template">
    <h2 id="modal-title">Cross-Modal Event Encoder: Bridging Image‚ÄìText Knowledge to Event Streams</h2>
    <p class="tags">Event-based Vision ¬∑ CLIP ¬∑ Cross-Modality ¬∑ Zero-Shot Learning</p>
    <p><strong>WACV 2026</strong> ¬∑ arXiv preprint (CoRR 2024)</p>
    <p>
      We extend CLIP's zero-shot and text-alignment capabilities to the event modality, developing a robust encoder that bridges asynchronous event data with image-text representations. The framework aligns event embeddings with CLIP's visual and textual spaces, preserving zero-shot generalization and enabling cross-modal applications across five modalities (Image, Event, Text, Sound, Depth).
    </p>
    <p><a href="https://arxiv.org/abs/2412.03093" target="_blank" rel="noopener">arXiv:2412.03093</a></p>
    
    <h3>Key Results</h3>
    <ul class="list">
      <li><strong>+19% zero-shot accuracy</strong> over prior event-based methods</li>
      <li>Cross-modal retrieval between event, sound, and depth modalities</li>
      <li>Event-based video anomaly detection without additional training</li>
      <li>Five-modality alignment: Image, Event, Text, Sound, Depth</li>
    </ul>

    <h3>Event-Specific Attention Visualization</h3>
    <p>
      Our visualization pipeline extracts attention heatmaps and relevance maps from the trained encoder, illustrating how CLIP's transferred attention captures salient event-specific regions. These visualizations demonstrate that the encoder successfully learns to focus on semantically meaningful areas in event data.
    </p>
    
    <div class="research-figures">
      <figure class="research-figure-single">
        <img src="assets/research/peacock_attention_imagenet.png" alt="Peacock attention heatmap on ImageNet" />
        <figcaption>Attention heatmap: Peacock (ImageNet) - Model attends to distinctive features like tail feathers and body structure</figcaption>
      </figure>
    </div>

    <div class="research-figures">
      <figure class="research-figure-single">
        <img src="assets/research/gramophone_attention_ncaltech.png" alt="Gramophone attention heatmap on N-Caltech" />
        <figcaption>Attention heatmap: Gramophone (N-Caltech) - Event encoder focuses on characteristic horn and base components</figcaption>
      </figure>
    </div>

    <div class="research-figures">
      <figure class="research-figure-single">
        <img src="assets/research/fight_tunnel_attention_UCFcrime.png" alt="Fight scene attention on UCF-Crime dataset" />
        <figcaption>Attention heatmap: Fight scene (UCF-Crime) - Model captures action regions for video anomaly detection</figcaption>
      </figure>
    </div>

    <h3>Technical Approach</h3>
    <p>
      The framework employs contrastive learning to align event representations with CLIP's pre-trained visual and textual embeddings. By leveraging CLIP's powerful multi-modal alignment, the encoder inherits zero-shot capabilities while learning event-specific features through asynchronous temporal patterns.
    </p>

    <h3>Cross-Modal Applications</h3>
    <ul class="list">
      <li><strong>Zero-Shot Classification:</strong> Direct transfer of text-based class descriptions to event data</li>
      <li><strong>Cross-Modal Retrieval:</strong> Query across image, event, text, sound, and depth modalities</li>
      <li><strong>Video Anomaly Detection:</strong> Event-based detection without task-specific training</li>
      <li><strong>Multi-Modal Fusion:</strong> Combine complementary information from different sensor types</li>
    </ul>

    <p><strong>My contribution:</strong> Supported the visualization pipeline by extracting attention heatmaps and relevance maps from the trained encoder, demonstrating how the model attends to salient event-specific regions across different datasets (ImageNet, N-Caltech, UCF-Crime).</p>
  </div>

  <div hidden id="modal-content-optimal-hdc" class="modal-content-template">
    <h2 id="modal-title">Optimal Hyperdimensional Representation for Learning and Cognitive Computation</h2>
    <p class="tags">Hyperdimensional Computing ¬∑ Cognitive Computation ¬∑ Neural-Symbolic Encoding</p>
    <p><strong>Frontiers in Artificial Intelligence (In Review)</strong></p>
    <p>
      This work introduces the first universal HDC encoding framework that adapts dynamically between learning and cognitive reasoning tasks. By modulating the correlation of hypervectors through tunable kernel scales, the model optimizes both memorization capacity and decodability, bridging the gap between symbolic reasoning and pattern learning within a unified high-dimensional representation.
    </p>

    <h3>Key Results</h3>
    <ul class="list">
      <li>Up to <strong>95% learning accuracy</strong> with correlated encodings vs. 65% in uncorrelated baselines</li>
      <li><strong>100% decoding accuracy</strong> under exclusive encodings for cognitive tasks</li>
      <li>Quantitative formulation of the correlation‚Äìseparation trade-off that governs brain-like reasoning</li>
      <li>Universal framework adaptable to both symbolic and pattern-based tasks</li>
    </ul>

    <h3>The Learning-Cognition Dichotomy</h3>
    <p>
      HDC systems face a fundamental trade-off: learning tasks benefit from correlated hypervector representations that enable generalization, while cognitive reasoning requires exclusive (orthogonal) encodings for symbolic manipulation. Traditional HDC methods optimize for one regime at the expense of the other. Our framework dynamically adapts encoding parameters to achieve optimal performance across both domains.
    </p>

    <h3>Learning Accuracy Analysis</h3>
    <p>
      We conducted comprehensive parameter sweeps to characterize how encoding dimensions (D) and kernel scales (w) affect learning performance. The heatmaps reveal distinct optimal regions: correlated encodings (smaller w values) dramatically improve learning accuracy, especially at lower dimensions where orthogonal encodings fail.
    </p>
    <div class="research-figures">
      <figure class="research-figure-single">
        <img src="assets/research/learning_accuracy.png" alt="Learning accuracy and separation heatmaps" />
        <figcaption>Learning accuracy (top) and separation (bottom) as functions of dimension D and kernel scale w. Correlated encodings (low w) achieve 95% accuracy, while maintaining measurable separation for downstream reasoning.</figcaption>
      </figure>
    </div>

    <h3>Decoding Accuracy Analysis</h3>
    <p>
      For cognitive tasks requiring symbolic manipulation, decoding accuracy depends on the exclusivity of hypervector encodings. Our analysis shows that higher kernel scales (larger w) produce more orthogonal representations, achieving 100% decoding accuracy. The 2D parameter space reveals the sweet spot where encodings are sufficiently exclusive for symbolic operations yet not overly sparse.
    </p>
    <div class="research-figures">
      <figure class="research-figure-single">
        <img src="assets/research/decoding_accuracy.png" alt="Decoding accuracy heatmaps" />
        <figcaption>Decoding accuracy as functions of D and w (left) and wx vs wy (right). Exclusive encodings (high w) enable perfect symbolic decoding, demonstrating the cognitive reasoning capability of the framework.</figcaption>
      </figure>
    </div>

    <h3>Signal-to-Noise Ratio Characterization</h3>
    <p>
      To formalize the correlation-separation trade-off, we analyzed the signal-to-noise ratio (SNR) distributions for both same-class and different-class hypervector pairs across varying dimensionality. The histograms reveal clear separation patterns: at higher dimensions (p=100), same-class pairs maintain high correlation while different-class pairs remain decorrelated, enabling both generalization and discrimination.
    </p>
    <div class="research-figures">
      <figure class="research-figure-single">
        <img src="assets/research/signal_to_noise.png" alt="Signal-to-noise ratio distributions" />
        <figcaption>SNR distributions for same-class (blue) and different-class (orange) hypervector pairs at p=10, 50, 100. Higher dimensionality provides better class separation while maintaining within-class correlation for generalization.</figcaption>
      </figure>
    </div>

    <h3>Technical Contribution</h3>
    <ul class="list">
      <li><strong>Universal Encoding Framework:</strong> Single parameterized system adaptable to learning and cognitive tasks</li>
      <li><strong>Tunable Correlation:</strong> Kernel scale parameters (w, wx, wy) modulate hypervector similarity</li>
      <li><strong>Theoretical Foundation:</strong> Mathematical formulation of the correlation-separation trade-off</li>
      <li><strong>Empirical Validation:</strong> Comprehensive parameter sweeps across dimensions and scales</li>
      <li><strong>Brain-Inspired Design:</strong> Mimics dual-process reasoning in biological neural systems</li>
    </ul>

    <h3>Applications</h3>
    <p>
      The adaptive HDC framework enables:
    </p>
    <ul class="list">
      <li><strong>Hybrid AI Systems:</strong> Seamlessly combine symbolic reasoning with pattern learning</li>
      <li><strong>Edge Computing:</strong> Lightweight, efficient representations for resource-constrained devices</li>
      <li><strong>Cognitive Architectures:</strong> Brain-inspired models balancing memory and reasoning</li>
      <li><strong>Neuromorphic Hardware:</strong> Optimized encodings for analog compute substrates</li>
    </ul>

    <p><strong>My contribution:</strong> Conducted decoding analyses and developed learning-accuracy heatmaps to visualize how encoding parameters affect separability and generalization. Collected and analyzed the signal-to-noise ratio distributions that support the theoretical derivation of optimal kernel scales for learning and cognition.</p>
  </div>

  <div hidden id="modal-content-efficient-hdc" class="modal-content-template">
    <h2 id="modal-title">Efficient Hyperdimensional Computing Eliminating Non-Linear Activations through Technology Non-Idealities</h2>
    <p class="tags">Hyperdimensional Computing ¬∑ Compute-in-Memory ¬∑ Neuromorphic Hardware ¬∑ Efficient AI</p>
    <p><strong>IEEE Transactions on Circuits and Systems I (In Submission)</strong></p>
    <p><em>Hamza Errahmouni Barkam, <strong>Xiangjian Liu</strong>, Tamoghno Das, Zhen Ye, Prathyush P. Poduval, Kai Ni, Mohsen Imani</em></p>
    <p>
      We introduce an energy-efficient Hyperdimensional Computing (HDC) framework that removes traditional non-linear activation functions by harnessing the inherent non-idealities of FeFET-based Computing-in-Memory (CIM) devices. Instead of treating device-level imperfections such as non-linear I‚ÄìV dependence and read noise as limitations, our design leverages them as computational resources‚Äîembedding activation behavior directly into hardware. This synergy between HDC's noise tolerance and CIM's parallelism results in a scalable, low-overhead system for edge AI applications.
    </p>

    <h3>Key Results</h3>
    <ul class="list">
      <li><strong>Eliminates costly non-linear activations</strong> by exploiting FeFET non-idealities</li>
      <li><strong>33‚Äì41% energy reduction</strong> and up to <strong>17% area savings</strong> through stacked complementary FeFET crossbars</li>
      <li>Maintains learning and decoding performance without dataset-specific tuning</li>
      <li>Tunable kernel width enables adaptive trade-offs between generalization and decoding precision</li>
      <li>Preserves HDC robustness under analog computation noise</li>
    </ul>

    <h3>Hardware-Embedded Activation</h3>
    <p>
      Traditional HDC frameworks rely on explicit sine and cosine activations to encode separable features. Our method substitutes these with <strong>Gaussian-shaped non-linear responses natively produced by FeFET devices</strong>. These responses modulate kernel width dynamically, creating a self-adjusting encoding process that balances learning efficiency and separability without extra compute steps.
    </p>
    <p>
      By exploiting the natural I-V characteristics of ferroelectric devices, we eliminate the need for:
    </p>
    <ul class="list">
      <li>Dedicated activation function hardware blocks</li>
      <li>High-precision analog-to-digital converters</li>
      <li>Separate digital processing stages for non-linearity</li>
    </ul>

    <h3>Computing-in-Memory Integration</h3>
    <p>
      We implement the system using <strong>complementary FeFET crossbar arrays</strong> capable of analog accumulation and direct Gaussian activation generation. The stacked crossbar architecture enables:
    </p>
    <ul class="list">
      <li><strong>Parallel In-Memory Computation:</strong> Eliminates data movement overhead between memory and compute</li>
      <li><strong>Complementary Operation:</strong> Reduces power consumption through push-pull FeFET configurations</li>
      <li><strong>Analog Processing:</strong> Native analog operations reduce quantization losses</li>
      <li><strong>Compact Design:</strong> 17% area reduction compared to conventional HDC accelerators</li>
    </ul>
    <p>
      By eliminating high-resolution ADCs and separate digital activation blocks, the design achieves significant gains in both energy efficiency (33-41% reduction) and silicon area.
    </p>

    <h3>Theoretical Insight</h3>
    <p>
      Combining kernel theory with <strong>Bochner's theorem</strong> and <strong>Random Fourier Features</strong>, the framework formalizes how hardware-induced non-linearities translate to tunable kernel properties. This mathematical foundation provides:
    </p>
    <ul class="list">
      <li><strong>Formal Equivalence:</strong> Proof that FeFET-generated Gaussian responses approximate ideal kernel functions</li>
      <li><strong>Tunable Kernels:</strong> Device parameters map directly to kernel width, enabling hardware-software co-optimization</li>
      <li><strong>Noise Tolerance:</strong> Theoretical analysis of how HDC's inherent robustness compensates for analog noise</li>
      <li><strong>Design Guidelines:</strong> Mathematical framework for co-designing algorithms and devices in neuromorphic architectures</li>
    </ul>

    <h3>Technical Innovation</h3>
    <ul class="list">
      <li><strong>Device-Algorithm Co-Design:</strong> First work to systematically exploit FeFET non-idealities as computational primitives in HDC</li>
      <li><strong>Activation-Free Architecture:</strong> Eliminates explicit activation functions through hardware embedding</li>
      <li><strong>Complementary FeFET Arrays:</strong> Novel crossbar design with push-pull operation for energy efficiency</li>
      <li><strong>Theoretical Framework:</strong> Mathematical formalization connecting device physics to kernel properties</li>
      <li><strong>Edge AI Optimization:</strong> Designed for resource-constrained embedded systems</li>
    </ul>

    <h3>Applications</h3>
    <p>
      The efficient HDC-CIM framework enables:
    </p>
    <ul class="list">
      <li><strong>IoT Edge Devices:</strong> Ultra-low-power inference for battery-powered sensors</li>
      <li><strong>Wearable Computing:</strong> Real-time processing with minimal energy consumption</li>
      <li><strong>Embedded AI:</strong> On-device learning without cloud connectivity</li>
      <li><strong>Neuromorphic Systems:</strong> Hardware substrate for brain-inspired computing paradigms</li>
      <li><strong>Autonomous Systems:</strong> Energy-efficient perception for drones and robotics</li>
    </ul>

    <h3>Impact on Hardware Design</h3>
    <p>
      This work challenges the traditional paradigm of viewing device non-idealities as limitations to overcome. Instead, it demonstrates that <strong>imperfections can become features</strong> when properly integrated into algorithm design. This philosophy opens new directions for:
    </p>
    <ul class="list">
      <li>Hardware-aware algorithm development that embraces rather than fights device physics</li>
      <li>Energy-efficient AI accelerators that minimize data movement and digital overhead</li>
      <li>Co-designed systems where hardware characteristics directly implement algorithmic primitives</li>
    </ul>

    <p><strong>My contribution:</strong> Co-author contributing to the theoretical analysis connecting device non-idealities to kernel properties, and validation of the framework's performance across different HDC encoding schemes.</p>
  </div>

  <div hidden id="modal-content-adamsfood-app" class="modal-content-template">
    <h2 id="modal-title">AdamsFoods Wholesale App</h2>
    <p class="tags">Full-Stack ¬∑ React ¬∑ Node.js ¬∑ AWS S3 ¬∑ JWT Auth</p>
    <p>
      A comprehensive full-stack JavaScript application built with a React client and Node.js/Express server. The application serves as a wholesale platform with robust product management and user authentication.
    </p>
    <h3>Key Features</h3>
    <ul class="list">
      <li><strong>Product Catalog:</strong> Complete product browsing and management system</li>
      <li><strong>Shopping Cart & Checkout:</strong> Fully functional cart system with checkout workflow skeleton</li>
      <li><strong>AWS S3 Integration:</strong> Seamless media and document workflows using signed URL uploads with intelligent caching</li>
      <li><strong>JWT Authentication:</strong> Secure token-based authentication with role-based access control</li>
      <li><strong>Admin Routes:</strong> Protected admin endpoints with role guards for sensitive operations</li>
      <li><strong>REST API:</strong> Well-structured REST endpoints organized under <code>/server</code></li>
    </ul>
    <p><a href="https://github.com/antsuh1028/AFStore" target="_blank" rel="noopener">View Code</a> ¬∑ <a href="https://adamsfoodswholesale.com/" target="_blank" rel="noopener">Live Website</a></p>
  </div>

  <div hidden id="modal-content-adamsfood-inventory" class="modal-content-template">
    <h2 id="modal-title">AdamsFoods Inventory Management System</h2>
    <p class="tags">React ¬∑ Vercel ¬∑ Inventory Management ¬∑ CRUD</p>
    <p>
      A React-based frontend application (Create React App) designed for back-office inventory tracking and stock management. Deployed on Vercel for reliable, fast access.
    </p>
    <h3>Features</h3>
    <ul class="list">
      <li><strong>Item CRUD Operations:</strong> Complete Create, Read, Update, Delete functionality for inventory items</li>
      <li><strong>Advanced Search & Filter:</strong> Powerful search capabilities to quickly locate items</li>
      <li><strong>Low-Stock Alerts:</strong> Automatic flagging of items with low inventory levels</li>
      <li><strong>CSV Export:</strong> Export-friendly views for reporting and data analysis</li>
      <li><strong>Interactive Map:</strong> 3D Map of warehouse storage rooms and item locations</li>
    </ul>
    <p><a href="https://github.com/antsuh1028/AdamsFoodsInventory" target="_blank" rel="noopener">View Code</a></p>
  </div>

  <div hidden id="modal-content-fph-dashboard" class="modal-content-template">
    <h2 id="modal-title">Feeding Pets of the Homeless Dashboard</h2>
    <p class="tags">Full-Stack ¬∑ React ¬∑ Node.js/Express ¬∑ Firebase Auth ¬∑ PostgreSQL</p>
    <p>
      Developed for the student organization <strong>Commit the Change (CTC)</strong> at University of California, Irvine in partnership with the non-profit <strong>Feeding Pets of the Homeless</strong>, this end-to-end donation-management platform tracks, visualizes, and authenticates donation flows across multiple regional chapters.
    </p>

    <h3>Key Features</h3>
    <ul class="list">
      <li><strong>Unified Web Frontend:</strong> Built with React and TypeScript powering donation dashboards, forms, and admin workflows with modern UI/UX</li>
      <li><strong>Secure Backend API:</strong> Node.js/Express with SQL/PostgreSQL routing, user authentication, and data aggregation endpoints</li>
      <li><strong>Role-Based Access Control:</strong> Chapter coordinators, donors, and admins each access customized UIs and views tailored to their needs</li>
      <li><strong>Firebase Authentication:</strong> Secure user authentication and authorization with Firebase Auth integration</li>
      <li><strong>PostgreSQL Database:</strong> Robust relational database design for donation tracking, user management, and chapter coordination</li>
      <li><strong>Multi-Chapter Support:</strong> Scales across multiple regional chapters with isolated data views and aggregated reporting</li>
    </ul>

    <h3>Development Practices</h3>
    <p>
      The project followed professional software engineering practices aligned with CTC's workflow:
    </p>
    <ul class="list">
      <li><strong>Git-Based Version Control:</strong> Branch management, merge-conflict resolution, and code reviews</li>
      <li><strong>Agile Development:</strong> Iterative sprints with regular stakeholder feedback and requirement refinement</li>
      <li><strong>CI/CD Alignment:</strong> Continuous integration and deployment practices ensuring code quality</li>
      <li><strong>Team Collaboration:</strong> Coordinated with multiple developers, designers, and project managers</li>
      <li><strong>Code Quality:</strong> Pull request reviews, testing standards, and documentation maintenance</li>
    </ul>

    <h3>Technical Architecture</h3>
    <ul class="list">
      <li><strong>Frontend:</strong> React with TypeScript, modern component architecture, state management, and responsive design</li>
      <li><strong>Backend:</strong> RESTful API built with Express.js, middleware for authentication and validation</li>
      <li><strong>Database:</strong> PostgreSQL with normalized schema design, efficient queries, and data integrity constraints</li>
      <li><strong>Authentication:</strong> Firebase Auth providing secure token-based authentication and role management</li>
      <li><strong>Deployment:</strong> Professional hosting setup with separate staging and production environments</li>
    </ul>

    <h3>Stakeholder Collaboration</h3>
    <p>
      Working directly with <strong>Feeding Pets of the Homeless</strong> coordinators required:
    </p>
    <ul class="list">
      <li><strong>Requirements Gathering:</strong> Understanding non-profit workflows and pain points in manual donation tracking</li>
      <li><strong>UX Alignment:</strong> Iterative design feedback to ensure accessibility for non-technical users</li>
      <li><strong>Deployment Iterations:</strong> Multiple release cycles incorporating real-world usage feedback</li>
      <li><strong>Training & Support:</strong> Creating documentation and providing training for chapter coordinators</li>
    </ul>

    <h3>Impact</h3>
    <p>
      The platform streamlines donation management for a national non-profit organization, enabling:
    </p>
    <ul class="list">
      <li>Real-time tracking of donations across multiple chapters</li>
      <li>Automated reporting and data visualization for coordinators</li>
      <li>Secure donor information management and authentication</li>
      <li>Scalable infrastructure supporting organizational growth</li>
      <li>Reduced administrative overhead through digital workflow automation</li>
    </ul>

    <p><strong>My contribution:</strong> Served as Full-Stack Developer (November 2023 ‚Äì June 2024). Bridged design ‚Üî implementation, delivered SQL routing and front-end features, and drove Git governance for branch quality and team collaboration. Coordinated with nonprofit stakeholders to ensure platform met both user and organizational goals.</p>
    <p>
      <a href="https://github.com/ctc-uci/fph-frontend" target="_blank" rel="noopener">Frontend Repository</a> ¬∑ 
      <a href="https://github.com/ctc-uci/fph-backend" target="_blank" rel="noopener">Backend Repository</a>
    </p>
  </div>

  <div hidden id="modal-content-navy-uav" class="modal-content-template">
    <h2 id="modal-title">Safe UAV Landing for U.S. Navy</h2>
    <p class="tags">Computer Vision ¬∑ Pose Estimation ¬∑ Reasoning ¬∑ CUI Dataset</p>
    <p>
      Through BiasLab & Prof. Mohsen Imani, I collaborated with the U.S. Navy to develop a custom computer vision system combining pose estimation and symbolic reasoning for safe autonomous UAV landing operations.
    </p>
    <h3>Problem Statement</h3>
    <p>
      Traditional UAV landing systems rely on legacy fixed-pattern optical markers, which perform poorly in adverse weather conditions, leading to increased casualty rates and mission failures. The Navy needed a more robust solution that could operate safely in challenging environments.
    </p>
    <h3>Solution</h3>
    <ul class="list">
      <li><strong>Pose Estimation Model:</strong> Custom-trained model for accurate UAV positioning relative to landing deck</li>
      <li><strong>Reasoning Module:</strong> Intelligent system that delays landing when crew members or obstacles are detected on the landing spot/deck</li>
      <li><strong>Weather Robustness:</strong> Significantly improved performance in bad weather conditions compared to legacy systems</li>
      <li><strong>Real-time Processing:</strong> Fast inference for time-critical landing decisions</li>
    </ul>
    <h3>Impact</h3>
    <p>
      The system reduces casualty rates by preventing landings when the deck is not clear, providing a crucial safety layer for naval aviation operations. Worked on CUI (Controlled Unclassified Information) dataset under appropriate clearances.
    </p>
  </div>

  <div hidden id="modal-content-crash-anticipation" class="modal-content-template">
    <h2 id="modal-title">Crash Anticipation</h2>
    <p class="tags">Computer Vision ¬∑ VideoMAE ¬∑ Autonomous Driving ¬∑ Neurosymbolic AI</p>
    <p>
      A cutting-edge video analysis system for predicting vehicle crashes before they occur, with future integration of neurosymbolic reasoning for actionable collision avoidance commands.
    </p>
    <h3>Current Performance (VideoMAE Baseline)</h3>
    <ul class="list">
      <li><strong>100% Accuracy:</strong> Perfect scores on AP (Average Precision), F1, and lead-time recall metrics</li>
      <li><strong>Real-time Inference:</strong> Capable of real-time processing with an NVIDIA 5070 Ti GPU</li>
      <li><strong>High Reliability:</strong> Demonstrated robust crash prediction across diverse scenarios</li>
    </ul>
    <h3>Current Limitations</h3>
    <p>
      The VideoMAE model's computational cost is too high for practical deployment on mobile devices or embedded systems in vehicles. This limits real-world applicability despite excellent performance.
    </p>
    <h3>Next Steps: Model Compression</h3>
    <p>
      Exploring smaller, more efficient models such as <strong>MobileNetV2.0</strong> that can run on resource-constrained devices while maintaining similar performance levels. Goal: Enable deployment on standard automotive hardware.
    </p>
    <h3>Future Direction: Neurosymbolic Reasoning</h3>
    <p>
      Beyond simple crash prediction, the vision is to integrate a <strong>symbolic reasoning module</strong> that can:
    </p>
    <ul class="list">
      <li><strong>Provide Direct Commands:</strong> Issue specific avoidance instructions (e.g., "turn left 15¬∞", "brake immediately", "accelerate to avoid rear collision")</li>
      <li><strong>Infer Vehicle Dynamics:</strong> Calculate incoming vehicle speed, trajectory, and direction in real-time</li>
      <li><strong>Reason About Scenarios:</strong> Use symbolic reasoning to evaluate multiple avoidance strategies and select optimal actions</li>
      <li><strong>Proactive Collision Avoidance:</strong> Transform from reactive warning system to proactive safety system that prevents crashes through intelligent intervention</li>
    </ul>
    <p>
      This neurosymbolic approach combines the perceptual power of deep learning with the interpretability and logical reasoning of symbolic AI, aligning with my broader research focus on neurosymbolic reasoning systems.
    </p>
    <p><a href="https://github.com/ShawnnnLiu/Crash-Anticipation" target="_blank" rel="noopener">View Code</a></p>
  </div>

  <div hidden id="modal-content-cat-collage" class="modal-content-template">
    <h2 id="modal-title">Coconut & Kumquat üê±üê±</h2>
    <p>Here are some of my favorite photos of my cats!</p>
    <div class="cat-collage">
      <img src="assets/cats/IMG_0021.JPG" alt="Cat photo" />
      <img src="assets/cats/IMG_5885.jpg" alt="Cat photo" />
      <img src="assets/cats/IMG_6085.jpg" alt="Cat photo" />
      <img src="assets/cats/IMG_6412.jpg" alt="Cat photo" />
      <img src="assets/cats/IMG_6549.jpg" alt="Cat photo" />
      <img src="assets/cats/IMG_6707.jpg" alt="Cat photo" />
      <img src="assets/cats/IMG_6722.jpg" alt="Cat photo" />
      <img src="assets/cats/IMG_6798.jpg" alt="Cat photo" />
      <img src="assets/cats/IMG_6803.jpg" alt="Cat photo" />
      <img src="assets/cats/IMG_6826.jpg" alt="Cat photo" />
      <img src="assets/cats/IMG_6960.jpg" alt="Cat photo" />
      <img src="assets/cats/IMG_6961.jpg" alt="Cat photo" />
      <img src="assets/cats/IMG_8631.jpg" alt="Cat photo" />
    </div>
  </div>

  <!-- Modal overlay -->
  <div id="modal" class="modal" aria-hidden="true">
    <div class="modal-backdrop" data-close></div>
    <div class="modal-dialog" role="dialog" aria-modal="true" aria-labelledby="modal-title">
      <button class="modal-close" data-close aria-label="Close">√ó</button>
      <div id="modal-body"></div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container">
      <p>¬© <span id="year"></span> Shawn Liu</p>
    </div>
  </footer>

  <script>
    // Modal helpers
    (function() {
      const modal = document.getElementById('modal');
      const body = document.getElementById('modal-body');
      function openModal(key) {
        const tpl = document.getElementById(`modal-content-${key}`);
        if (!tpl) return;
        body.innerHTML = tpl.innerHTML;
        modal.classList.add('open');
        modal.setAttribute('aria-hidden', 'false');
        document.body.style.overflow = 'hidden';
      }
      function closeModal() {
        modal.classList.remove('open');
        modal.setAttribute('aria-hidden', 'true');
        body.innerHTML = '';
        document.body.style.overflow = '';
      }
      modal.addEventListener('click', (e) => {
        if (e.target.matches('[data-close]')) closeModal();
      });
      document.addEventListener('keydown', (e) => {
        if (e.key === 'Escape') closeModal();
      });
      document.addEventListener('click', (e) => {
        const link = e.target.closest('.read-more, .read-more-btn, .clickable-image');
        if (!link) return;
        e.preventDefault();
        const key = link.getAttribute('data-modal');
        openModal(key);
      });
    })();

    // Carousel scroll function
    function scrollCarousel(direction) {
      const carousel = document.querySelector('.cards-carousel');
      const cardWidth = 320; // card width + gap
      const scrollAmount = (cardWidth + 16) * direction;
      carousel.scrollBy({ left: scrollAmount, behavior: 'smooth' });
    }

    document.getElementById('year').textContent = new Date().getFullYear();
    // Optional publications rendering (only if #pubs exists)
    (function() {
      const wrap = document.getElementById('pubs');
      if (!wrap) return;
      fetch('publications.json')
        .then(r => r.json())
        .then(items => {
          if (!Array.isArray(items) || items.length === 0) {
            wrap.innerHTML = '<p>No publications yet.</p>';
            return;
          }
          wrap.innerHTML = '';
          items.forEach(p => {
            const el = document.createElement('div');
            el.className = 'pub';
            const authors = (p.authors || []).join(', ');
            const venue = [p.venue, p.year].filter(Boolean).join(', ');
            el.innerHTML = `
              <p class="title">${p.title || ''}</p>
              <p class="by">${authors}</p>
              <p class="venue">${venue}</p>
              <p class="links">
                ${p.doi ? `<a href="${p.doi}" target="_blank" rel="noopener">DOI</a>` : ''}
                ${p.arxiv ? `<a href="${p.arxiv}" target="_blank" rel="noopener">arXiv</a>` : ''}
                ${p.code ? `<a href="${p.code}" target="_blank" rel="noopener">Code</a>` : ''}
                ${p.poster ? `<a href="${p.poster}" target="_blank" rel="noopener">Poster</a>` : ''}
              </p>`;
            wrap.appendChild(el);
          });
        })
        .catch(() => { if (wrap) wrap.innerHTML = '<p>(Could not load publications.json)</p>'; });
    })();

    // (demos removed; single GIF is rendered statically in markup)
  </script>
</body>
</html>
